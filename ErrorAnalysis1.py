"""
deeplabcut tools for data analysis

Created by Nicholas Thomas
Last Edited 7/29/19

Notes for points of improvement. Change in paramaters to pass in. Accepting files, or config file
and going from there

filepath is currently a mandatory parameter

function list:
quantifyErrors(trueLabels, testLabels, threshold, filepath, split=False, getParams=False)
testThresholds(trueLabels, testLabels, thresholds, filepath)
plotErrors(trueLabels, testLabels, thresholds, filepath, snapshots=[] , save=True, normalize=True)
"""


import numpy as np
import pandas as pd
import os
import math
import time
import sys
from pathlib import Path

#Matplotlib Configuration
import seaborn as sb
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
matplotlib.use('WxAgg')

import sklearn.metrics as sk

#True Positive, True Negative, False Positive, False Negative
errorTypes = ['TP', 'TN', 'FP', 'FN']

def quantifyErrors(trueLabels, testLabels,  filepath, threshold=.1, getParams=False, filter=True):
    """Short summary.

    Calculates the errors on the deeplabcut training and test data. Classifies each label as True
    Positive (TP), True Negative (TN), False Positive (FP), or False Negative (FN). For each true
    Positive the distance between the true (manually labeled) points and the dlc labeled points is
    calculated

    Parameters
    ----------
    trueLabels : type = panda, or path to hdf file
        Manually labeled data. This is the "ground" truth against which the test labels
        are compared to. Includes just an x and y coordinate for each label in each frame,
        the coordinate value is Nan if the label is not included in that frame.
    testLabels : type = panda, or path to hdf file
        The labels generated by deeplabcut. includes an x,y, and confidence for each label
        for each frame.
    threshold : type = double
        The pcutoff or threshold above which labels are included for a frame. Value must be
        between 0 and 1. Default is .1
    filepath : type = string
        The file path to the folder of all the frames which include test or train in their
        labels.
    getParams : type = boolean
        If true, returns a dictionary with parameters
    filter : type = boolean
        If true, will filter the test labels. Any True positive label with a distance greater than
        (mean + 1.5*IQR) will be reclassified as a false positive and its corresponding
        distance set to nan - IQR is interquartile range. The mean and IQR are calculated for each
        individual label

    Returns
    -------
    results : type = pandas
        Columns: [Type] [[Label Names], [ErrorType, Confidence, Distance]]
     frame by frame description of the data and errors (Raw Error Analysis)

    SnS: by label description of the data (Sensitivity and Specificity Matrix)

    (Optional Returns)
    parameters: {labels: [] of '', numLabels: int, numFrames: int }

    """
    np.warnings.filterwarnings('ignore')

    trueLabels, testLabels = __checkInput(trueLabels, testLabels)

    #Ensures that the threshold is between 0 and 1
    if(threshold > 1 or threshold < 0):
        raise Exception('threshold must be between the values of 0 and 1 inclusive;'
                        ' you passed in threshold={}'.format(threshold)
                        )

    #Parameters
    labels = trueLabels.columns.get_level_values(1)[0::2].tolist() #Retrieves the label names
    numLabels = len(labels) #Number of Labels
    numFrames = np.shape(trueLabels)[0] #Number of frames in the dataset

    parameters = {'labels':labels, 'numLabels':numLabels, 'numFrames':numFrames}

    #Note, DLC creates a folder with the frames labeled as test and as train
    #The filepath references that folder. A dictionary is created which has the key as
    #the frame number and the value as the frame type  (test or train) to differentiate
    #the two
    frameNames = os.listdir(filepath)
    frameType = {}
    for f in frameNames:
        #frame name ex: Type-VidName-img####.png -> ['Type', VidName, img####]
        frameName = f.split('-')
        frameType[frameName[2][:-4]] = frameName[0] #[:-4] removes '.png'

    header = pd.MultiIndex.from_product([labels, ['Error Type','Confidence', 'Distance']])
    indices = list(frameType.keys())
    results = pd.DataFrame(index = indices, columns = header)
    results.insert(0, 'Type',frameType.values())
    results = results.sort_index()
    #The results dataframe is nan except for the Type (Train or Test)

    trueVals = trueLabels.values
    testVals = testLabels.values

    testConfidences = testVals[:,2::3] #confidence for each test label
    testValsXY = np.delete(testVals, list(range(2,testVals.shape[1], 3)), axis=1) #XY coords
    thresholdTest = (testConfidences > threshold) #Indices of labels greater than threshold
    labelTest = pd.isnull(trueVals)[:,::2] #Indices of labels that should not be included

    #when a label is nan it means it should not be plotted (it should be a negative)
    tp = np.multiply(thresholdTest,~labelTest)      #greater than threshold, should be plotted
    fp = np.multiply(thresholdTest, labelTest)      #greater than threshold, should not be plotted
    fn = np.multiply(~thresholdTest, ~labelTest)    #lower than threshold, should be plotted
    tn = np.multiply(~thresholdTest, labelTest)     #lower than threshold, should not be plotted

    #Initializing error Matrix for each label across each frame
    errors = np.empty((numFrames, numLabels), dtype = object)
    errors[tp] = "TP" #True Positive
    errors[fp] = "FP" #False Positive
    errors[fn] = "FN" #False Negatives
    errors[tn] = "TN" #True Negatives

    #This clusters takes sequential xy values and makes them pairs for true positive labels.
    #Original shape: (numFrames, numLables*2)
    XY1 = trueVals.reshape(numFrames, numLabels, 2)[tp]
    XY2 = testValsXY.reshape(numFrames, numLabels, 2)[tp]

    dist = sk.pairwise.paired_distances(XY1,XY2) #1D array of length # of True Positives
    dist2 = np.full(numFrames*numLabels, np.nan)
    dist2[tp.flatten()] = dist  #Makes tp 1D in order to retrieve all tp indices to set to
                                #corresponding distance

    dist2[dist2>50] = math.nan #hard Filter Limit
    dist2 = dist2.reshape(numFrames,numLabels)

    #Each label has three values: Error Type, Confidence, and distance. Thus the indexing by three.
    #Errors start at column 1 as column 0 is the training or test identification
    results.iloc[:,1::3] = errors
    results.iloc[:,2::3] = testConfidences
    results.iloc[:,3::3] = dist2

    if filter:
        resVals = results[results['Type']=='Test'].iloc[:,3::3]

        IQR = resVals.quantile(.75) - resVals.quantile(.25)
        distThresholds =resVals.mean() + 1.5*IQR

        resBool = (resVals > distThresholds).values
        resVals = resVals.values
        resVals[resBool] = np.nan
        results.ix[results['Type'] == 'Test', 3::3] = resVals
        err = results.ix[results['Type'] == 'Test', 1::3].values
        err[resBool] = 'FP'
        results.ix[results['Type'] == 'Test', 1::3] = err
        resVals = results[results['Type']=='Training'].iloc[:,3::3]

        IQR = resVals.quantile(.75) - resVals.quantile(.25)
        distThresholds =resVals.mean() + 1.5*IQR

        resBool = (resVals > distThresholds).values
        resVals = resVals.values
        resVals[resBool] = np.nan
        results.ix[results['Type'] == 'Training', 3::3] = resVals
        err = results.ix[results['Type'] == 'Training', 1::3].values
        err[resBool] = 'FP'
        results.ix[results['Type'] == 'Training', 1::3] = err

    header = pd.MultiIndex.from_product([['Training', 'Test'], errorTypes])
    SnS = pd.DataFrame(index = labels, columns = header) #Sns: Specificity and Sensitivity
    SnS = SnS.fillna(0)

    testErr = results[results['Type'] == 'Test'].iloc[:,1::3]
    trainErr = results[results['Type'] == 'Training'].iloc[:,1::3]
    for i, errorType in enumerate(errorTypes):
        SnS.iloc[:,i] = (trainErr == errorType).sum().values
        SnS.iloc[:,i+4] = (testErr == errorType).sum().values

    if(getParams):
        return results, SnS, parameters
    else:
        return results, SnS

def testThresholds(trueLabels, testLabels, filepath, thresholds = [], filter=True):
    """Short summary.

    Calculates the errors at several different thresholds

    Parameters
    ----------
    trueLabels : type = panda, or path to hdf file
        Manually labeled data. This is the "ground" truth against which the test labels
        are compared to. Includes just an x and y coordinate for each label in each frame,
        the coordinate value is Nan if the label is not included in that frame.
    testLabels : type = panda, or path to hdf file
        The labels generated by deeplabcut. includes an x,y, and confidence for each label
        for each frame.
    threshold : type = [] of doubles
        An array of thresholds above which labels are included for a frame. Values must be
        between 0 and 1.
    filepath : type = string
        The file path to the folder of all the frames which include test or train in their
        labels.

    Returns
    -------
    avgOccurences (panda): the average of the occurences of error type and respective confidences
                          taken across all labels at a threshold
    distances (panda): for each label, calculates the average distance and standard deviations
                       between the manually labeled points and the dlc labled points
    snapshots ([] of pandas): an array of SnS pandas at the different thresholds

    """

    #Ensures treshold type
    if not isinstance(thresholds, (list, np.ndarray) ):
        raise Exception('thresholds was of the incorrect type. You passed in a [{}] when it should '
                        'have been a list or np.ndarray'.format(str(type(thresholds))[8:-2]))

    #Ensures thresholds is an nparray for boolean checking. Also sorts values in ascending order
    thresholds = np.sort(np.asarray(thresholds))

    #Checks to make sure there is more than 1 value in thresholds
    if thresholds.size<2:
        raise Exception('thresholds is a singular value of {}, not an array or list of multiple '
                        'values'.format(thresholds))

    #Checks that the array is not multi dimensional
    if thresholds.shape != thresholds.flatten().shape:
        raise Exception('you passed in a multidimensional array instead of a 1D list or array')


    t_Below = thresholds[(thresholds<0)] #values less than 0
    t_Above = thresholds[(thresholds>1)] #values greater than 1

    #Checks if any thresholds are repeated
    for i,t in enumerate(thresholds[:-1]):
        if t == thresholds[i+1]:
            raise Exception('{} is a repeated value. Tresholds should only contain unique values '
                            'between 0 and 1'.format(t))

    #Ensures no threshold value is below 0
    if t_Below.size>0:
        raise Exception('{} are below threshold minimum of 0'.format(t_Below))
    #Ensures no threshold value is above 1
    if t_Above.size>0:
        raise Exception('{} are above threshold maximum of 1'.format(t_Above))

    header = pd.MultiIndex.from_product([['Training', 'Test'], errorTypes])
    avgOccurences = pd.DataFrame(index = thresholds[:-1], columns = header)

    snapshots = []
    labels = []

    for i, t in enumerate(thresholds[:-1]):
        results, SnS, params = quantifyErrors(trueLabels, testLabels, filepath, threshold=t,
                                     getParams=True, filter=filter)

        #initializes the distances matrix, pulls the labels from the first call of quantifyErrors in
        #the first iteration of the loop
        if(i == 0):
            labels = params['labels']
            subHeader = ['Average'] + labels
            header = pd.MultiIndex.from_product([['Training', 'Test'], subHeader,
                                                 ['Distance', 'Standar Deviation']])
            distances = pd.DataFrame(index = thresholds[:-1], columns = header)

        avgOccurences.iloc[i] = list(round(SnS.mean(), 4))
        tempTrainData = results[results['Type'] == 'Training'].iloc[:,3::3] #gets Train distances
        tempTestData = results[results['Type'] == 'Test'].iloc[:,3::3] #gets Test distances
        trainDist = tempTrainData.mean().values.tolist()
        testDist = tempTestData.mean().values.tolist()
        trainVar = tempTrainData.std().values.tolist()
        testVar = tempTestData.std().values.tolist()
        trainDist.insert(0, np.mean(trainDist))
        testDist.insert(0, np.mean(testDist))
        trainVar.insert(0, np.nanstd(tempTrainData, dtype = float))
        testVar.insert(0, np.nanstd(tempTestData, dtype = float))
        distances.iloc[i, ::2] = trainDist+testDist
        distances.iloc[i,1::2] = trainVar+testVar
        snapshots.append(SnS)


    return avgOccurences, distances, snapshots

def score(trueLabels, testLabels, filepath, thresholds=[], filter=True):
    results, SnS, params = quantifyErrors(trueLabels, testLabels, filepath, getParams = True)
    occ, distances, snapshots = testThresholds(trueLabels, testLabels, filepath,
                                              thresholds=thresholds, filter=filter)

    scores = pd.DataFrame(index = thresholds[:-1], columns = params['labels'] )
    numTestFrames = 0

    label = params['labels']
    err1 = []

    for i,s in enumerate(snapshots):
        numOcc = s['Test'].values
        if i==0:
            numTestFrames = numOcc[0].sum()
        errSum = numOcc[:,1] - numOcc[:,2] - numOcc[:,2]
        err1.append(errSum)
        labels = params['labels']
        tp = numOcc[:,0]
        dists = np.asarray(distances['Test'].iloc[i, 2::2], dtype = 'float64')
        std = np.asarray(distances['Test'].iloc[i, 3::2], dtype = 'float64')

        weights = (3 / dists)**2

        score = np.multiply(weights, (tp+errSum))/numTestFrames
        scores.iloc[i] = np.asarray(score)
    variableThresholds = np.asarray(scores.astype("float").idxmax())
    labelScores = {}
    scoreSum = 0
    for i,t in enumerate(variableThresholds):
        score = scores.loc[t,label[i]]
        labelScores[label[i]] = {"Threshold":np.round(t, 2), "Score":score}
        scoreSum += score
    finalScore = scoreSum / len(variableThresholds)
    return scores, labelScores, finalScore


def plotDistanceDistribution(trueLabels, testLabels, filepath, threshold = .1, filter=True,
                            type='Test'):

    results, SnS, params = quantifyErrors(trueLabels, testLabels, filepath, getParams=True,
                                            filter = filter)
    sb.set(style="ticks")
    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={"height_ratios": (.15, .85)})
    bins = np.linspace(0,100,201) #.5 width bins

    for i,label in enumerate(params['labels']):
        tempResults = results[results['Type']==type].iloc[:,(i+1)*3 ].values
        x = tempResults[~pd.isnull(tempResults)]

        sb.boxplot(x, ax=ax_box)
        sb.distplot(x, ax=ax_hist, bins=bins)

        ax_box.set(yticks=[])
        sb.despine(ax=ax_hist)
        sb.despine(ax=ax_box, left = True)

        plt.title(label)
        plt.xlim(0,50)
        plt.xlabel('Distance (pixels)')
        plt.waitforbuttonpress()
        ax_box.clear()
        ax_hist.clear()

def violinplot(trueLabels, testLabels, filepath, filter = True, threshold=.1,type='Test' ):
    """
    if filter != "compare" and isinstance(filter, (str)):
        raise Exception('filter is an invalid string. It must be either a boolean or the string'
                        ' "compare". You passed in filter: {}'.format(filter))
    elif not isinstance(filter, boolean):
        raise exception('filter is of the incorrect type. It must be either a boolean or the string'
                        ' "compare". You passed in filter of type {}'.format(type(filter))
    """
    #Compares filter and filtered distance distrutions
    if (filter == 'compare'):
        resultsFilt, SnS, params = quantifyErrors(trueLabels,testLabels, filepath, getParams=True,
                                                filter=True, threshold = threshold)
        resultsRaw, SnSRaw = quantifyErrors(trueLabels,testLabels, filepath, getParams=False,
                                            filter=False, threshold = threshold)

        XFilt = resultsFilt[resultsFilt['Type']==type].iloc[:,3::3]
        labels = XFilt.columns.get_level_values(0)
        XFilt.columns = XFilt.columns.droplevel(1)

        XRaw = resultsRaw[resultsRaw['Type']==type].iloc[:,3::3]
        XRaw.columns = XRaw.columns.droplevel(1)

        nR = pd.isnull(XRaw).sum().sum()
        nF = pd.isnull(XFilt).sum().sum()
        ndf2 = np.empty(((nR+nF), 3), dtype = object)
        index = 0

        #Reorganizing data so that it can be plotted using violin plots
        for label in labels:
            xR = XRaw[label].values
            xR = xR[~pd.isnull(xR)]
            xF = XFilt[label].values
            xF = xF[~pd.isnull(xF)]

            lenR = len(xR)
            ndf2[index:index+lenR,0] = label
            ndf2[index:index+lenR,1] = xR
            ndf2[index:index+lenR,2] = "Unfiltered"
            index += lenR

            lenF = len(xF)
            ndf2[index:index+lenF,0] = label
            ndf2[index:index+lenF,1] = xF
            ndf2[index:index+lenF,2] = "Filtered"
            index += lenF

        df = pd.DataFrame(columns = ['label', 'Distance', 'Filt'], data = ndf2)
        sb.set(style="ticks")
        df['Distance'] = df['Distance'].astype(float)
        ax = sb.violinplot(y=df['Distance'], x=df['label'], data=df,split=True, hue='Filt', cut=0,
                        inner="quartile", palette={"Filtered":'azure',"Unfiltered":'lightcoral'})
        title = "Comparison of filtered and Unfiltered"

    #No comparison of data, can be filtered or unfiltered distributions
    else:
        results, SnS, params = quantifyErrors(trueLabels,testLabels, filepath, getParams=True,
                                                    filter=filter, threshold = threshold)
        X = results[results['Type']==type].iloc[:,3::3]
        labels = X.columns.get_level_values(0)
        X.columns = X.columns.droplevel(1)
        sb.violinplot(data=X, cut=0, inner = 'quartile')
        plt.xlabel('Distance')
        if filter:
            title = "Filtered"
        else:
            title = "Unfiltered"


    plt.title("{} Distance Distribution for each Label at threshold: {}".format(title, threshold))
    plt.ylim(0,50)

    plt.show()


def plotSnS(trueLabels, testLabels, thresholds, filepath, snapshots=[] , save=True,
               normalize=True, manual = True):
    """Short summary.

    Parameters
    ----------
    trueLabels : type
        Description of parameter `trueLabels`.
    testLabels : type
        Description of parameter `testLabels`.
    thresholds : type
        Description of parameter `thresholds`.
    filepath : type
        Description of parameter `filepath`.
    snapshots : type
        Description of parameter `snapshots`.
    save : type
        Description of parameter `save`.
    normalize : type
        Description of parameter `normalize`.

    Returns
    -------
    type
        Description of returned object.

    """

    matplotlib.use('WXAgg')

    #If you do not pass in the snapshots
    if not snapshots:
        avgOccurences, distances, snapshots = testThresholds(trueLabels, testLabels, filepath, thresholds)

    plt.style.use('fivethirtyeight')

    #ani = FuncAnimation(plt.gcf(), __animate2, fargs=(snapshots, normalize, thresholds,), interval=2000)

    fig = plt.figure(1)

    for i in range(len(thresholds)):
        if manual:
            keypress = False
            while not keypress:
                keypress = plt.waitforbuttonpress()
        else:
            plt.pause(1)
        __animate(i,snapshots, normalize, thresholds)

    plt.close()

    #Need to fix writer
    #Writer = matplotlib.animation.writers['ffmpeg']
    #writer = Writer(fps=1)

    #plt.show()
    #ani.save('Error Data.mp4', writer=writer, dpi=1200)

#WIP  in notebooks in different forms. Need more data to continue working on it.
#def Score(snapshots, thresholds, ):


#Private Methods and helper functions (Do Not Call)
#-------------------------------------------------------------------------------------------------#
def __animate(i, snapshots, normalize, thresholds):
    print(i) #Should be printed. Helps ensure plotting is occuring
    fontSize = [14,10,20]
    barWidth = .4
    b = snapshots[i]
    n_groups = b.shape[0]
    if(normalize):
        normalizer = [b['Training'].iloc[0,:].sum(), b['Test'].iloc[0,:].sum()]
    else:
        normalizer = [1,1]
    fig = plt.figure(1)
    plt.suptitle("Threshold: " + str(round(thresholds[i],4)), fontsize = fontSize[0])

    for j, errorType in enumerate(errorTypes):
        #fig, ax = plt.subplots()
        plt.subplot(2,2,j+1)
        plt.cla()
        index = np.arange(n_groups)

        r1 = plt.bar(index, (b['Training'][errorType]) / normalizer[0],
                     barWidth, label = 'Training')

        r2 = plt.bar(index + barWidth, (b['Test'][errorType]) / normalizer[1],
                     barWidth, label = 'Test')

        plt.xlabel('Label', fontsize = fontSize[0])
        plt.ylabel('% of Labels', fontsize = fontSize[0])
        plt.ylim(0, 1)
        plt.title('Training vs Test Comparison: ' + errorType, fontsize = fontSize[0])
        plt.xticks(index + barWidth/2, (b.index), fontsize = fontSize[0])
        plt.yticks(fontsize = fontSize[0])
        plt.legend(fontsize = fontSize[0])
        #fig.canvas.draw()
        plt.tight_layout()

def __checkInput(trueLabels, testLabels):
    #Ensures true and test labels are correct data type
    if not all(map(lambda x : isinstance(x, (pd.DataFrame, Path, str)), [trueLabels, testLabels])):
        raise Exception('true and test labels must be either a panda dataframe or the h5 output '
                        'files created when training the network. For trueLabels you passed in a '
                        '{} and for testLabels you passed in a {}'.format(str(type(trueLabels)),
                                                                          str(type(testLabels)))
                       )

    #If trueLabels or Testlabels are files, reads them and outputs pandas
    if not isinstance(trueLabels, pd.DataFrame):
        trueLabels = pd.read_hdf(trueLabels)
    if not isinstance(testLabels, pd.DataFrame):
        testLabels = pd.read_hdf(testLabels)

    return trueLabels, testLabels
