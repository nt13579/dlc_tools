"""
deeplabcut tools for data analysis

Created by Nicholas Thomas
Last Edited 7/29/19

Notes for points of improvement. Change in paramaters to pass in. Accepting files, or config file
and going from there

filepath is currently a mandatory parameter

function list:
quantifyErrors(trueLabels, testLabels, threshold, filepath, split=False, getParams=False)
testThresholds(trueLabels, testLabels, thresholds, filepath)
plotErrors(trueLabels, testLabels, thresholds, filepath, snapshots=[] , save=True, normalize=True)
"""


import numpy as np
import pandas as pd
import os
import math
import time
import sys
from pathlib import Path

#Matplotlib Configuration
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
matplotlib.use('WxAgg')

import sklearn.metrics as sk

#True Positive, True Negative, False Positive, False Negative
errorTypes = ['TP', 'TN', 'FP', 'FN']

def quantifyErrors(trueLabels, testLabels,  filepath, threshold = .1, getParams=False, edit=True, coeff = 1):
    """Short summary.

    Calculates the errors on the deeplabcut training and test data. Classifies each label as True
    Positive (TP), True Negative (TN), False Positive (FP), or False Negative (FN). For each true
    Positive the distance between the true (manually labeled) points and the dlc labeled points is
    calculated

    Parameters
    ----------
    trueLabels : type = panda, or path to hdf file
        Manually labeled data. This is the "ground" truth against which the test labels
        are compared to. Includes just an x and y coordinate for each label in each frame,
        the coordinate value is Nan if the label is not included in that frame.
    testLabels : type = panda, or path to hdf file
        The labels generated by deeplabcut. includes an x,y, and confidence for each label
        for each frame.
    threshold : type = double
        The pcutoff or threshold above which labels are included for a frame. Value must be
        between 0 and 1. Default is .1
    filepath : type = string
        The file path to the folder of all the frames which include test or train in their
        labels.
    getParams : type = boolean
        If true, returns a dictionary with parameters

    Returns
    -------
    results: frame by frame description of the data and errors (Raw Error Analysis)
    SnS: by label description of the data (Sensitivity and Specificity Matrix)

    (Optional Returns)
    parameters: {labels: [] of '', numLabels: int, numFrames: int }

    """
    trueLabels, testLabels = __checkInput(trueLabels, testLabels)

    #Ensures that the threshold is between 0 and 1
    if(threshold > 1 or threshold < 0):
        raise Exception('threshold must be between the values of 0 and 1 inclusive;'
                        ' you passed in threshold={}'.format(threshold)
                        )

    #Parameters
    labels = trueLabels.columns.get_level_values(1)[0::2].tolist() #Retrieves the label names
    numLabels = len(labels) #Number of Labels
    numFrames = np.shape(trueLabels)[0] #Number of frames in the dataset

    parameters = {'labels':labels, 'numLabels':numLabels, 'numFrames':numFrames}

    #Note, DLC creates a folder with the frames labeled as test and as train
    #The filepath references that folder. A dictionary is created which has the key as
    #the frame number and the value as the frame type  (test or train) to differentiate
    #the two
    frameNames = os.listdir(filepath)
    frameType = {}
    for f in frameNames:
        #frame name ex: Type-VidName-img####.png -> ['Type', VidName, img####]
        frameName = f.split('-')
        frameType[frameName[2][:-4]] = frameName[0] #[:-4] removes '.png'

    header = pd.MultiIndex.from_product([labels, ['Error Type','Confidence', 'Distance']])
    indices = list(frameType.keys())
    results = pd.DataFrame(index = indices, columns = header)
    results.insert(0, 'Type',frameType.values())
    results = results.sort_index()
    #The results dataframe is nan except for the Type (Train or Test)

    trueVals = trueLabels.values
    testVals = testLabels.values

    testConfidences = testVals[:,2::3] #confidence for each test label
    testValsXY = np.delete(testVals, list(range(2,testVals.shape[1], 3)), axis=1) #XY coords
    thresholdTest = (testConfidences > threshold) #Indices of labels greater than threshold
    labelTest = np.isnan(trueVals)[:,::2] #Indices of labels that should not be included

    #when a label is nan it means it should not be plotted (it should be a negative)
    tp = np.multiply(thresholdTest,~labelTest)      #greater than threshold, should be plotted
    fp = np.multiply(thresholdTest, labelTest)      #greater than threshold, should not be plotted
    fn = np.multiply(~thresholdTest, ~labelTest)    #lower than threshold, should be plotted
    tn = np.multiply(~thresholdTest, labelTest)     #lower than threshold, should not be plotted

    #Initializing error Matrix for each label across each frame
    errors = np.empty((numFrames, numLabels), dtype = object)
    errors[tp] = "TP" #True Positive
    errors[fp] = "FP" #False Positive
    errors[fn] = "FN" #False Negatives
    errors[tn] = "TN" #True Negatives

    #This clusters takes sequential xy values and makes them pairs for true positive labels.
    #Original shape: (numFrames, numLables*2)
    XY1 = trueVals.reshape(numFrames, numLabels, 2)[tp]
    XY2 = testValsXY.reshape(numFrames, numLabels, 2)[tp]

    dist = sk.pairwise.paired_distances(XY1,XY2) #1D array of length # of True Positives
    dist2 = np.full(numFrames*numLabels, np.nan)
    dist2[tp.flatten()] = dist  #Makes tp 1D in order to retrieve all tp indices to set to
                                #corresponding distance
    dist2 = dist2.reshape(numFrames,numLabels)

    #Each label has three values: Error Type, Confidence, and distance. Thus the indexing by three.
    #Errors start at column 1 as column 0 is the training or test identification
    results.iloc[:,1::3] = errors
    results.iloc[:,2::3] = testConfidences
    results.iloc[:,3::3] = dist2

    if edit:
        resVals = results[results['Type']=='Test'].iloc[:,3::3].values
        tempDist = resVals.flatten()
        tempDist = tempDist[~np.isnan(tempDist)]

        bins = np.linspace(0,100,201) #.5 width bins
        counts, bins2 = np.histogram(tempDist, bins=bins)
        bins = bins2[1::] #removes 0 bin and makes counts and bins2 the same size
        weights = np.multiply(bins,counts)
        differences = []
        for i in range(len(bins)):
            tot1 = np.sum(weights[0:i])
            tot2 = np.sum(weights[i::]) * coeff
            differences.append(abs(tot2-tot1))
        distThreshold = np.argmin(np.asarray(differences))/2

        #resVals = results[results['Type'] == 'Test'].iloc[:,3::3].values
        np.warnings.filterwarnings('ignore')
        resBool = resVals > distThreshold
        resVals[resBool] = np.nan
        results.ix[results['Type'] == 'Test', 3::3] = resVals
        err = results.ix[results['Type'] == 'Test', 1::3].values
        err[resBool] = 'FP'
        results.ix[results['Type'] == 'Test', 1::3] = err

    header = pd.MultiIndex.from_product([['Training', 'Test'], errorTypes,
                                         ['# Occurences','Avg Confidence']])
    SnS = pd.DataFrame(index = labels, columns = header) #Sns: Specificity and Sensitivity

    for i, label in enumerate(labels):
        trainCounts = []
        testCounts = []
        for errorType in errorTypes:
            trainData = results[results['Type'] == 'Training'][label].values
            testData = results[results['Type'] == 'Test'][label].values
            trainCount = [0,math.nan] #[Number of Occurences, Avg Confidence]
            testCount = [0,math.nan] #[Number of Occurences, Avg Confidence]
            trainCount[0] = list(trainData[:,0]).count(errorType)
            testCount[0] = list(testData[:,0]).count(errorType)
            if(trainCount[0] > 0):
                trainCount[1] = round(np.mean([trainData[trainData[:,0] == errorType][:,1]]), 4)
            if(testCount[0] > 0):
                testCount[1] = round(np.mean([testData[testData[:,0] == errorType][:,1]]), 4)
            trainCounts.extend(trainCount)
            testCounts.extend(testCount)
        SnS.iloc[i] = trainCounts + testCounts

    if(getParams):
        return results, SnS, parameters
    else:
        return results,SnS

def testThresholds(trueLabels, testLabels, thresholds, filepath, edit=True, coeff= 1):
    """Short summary.

    Calculates the errors at several different thresholds

    Parameters
    ----------
    trueLabels : type = panda, or path to hdf file
        Manually labeled data. This is the "ground" truth against which the test labels
        are compared to. Includes just an x and y coordinate for each label in each frame,
        the coordinate value is Nan if the label is not included in that frame.
    testLabels : type = panda, or path to hdf file
        The labels generated by deeplabcut. includes an x,y, and confidence for each label
        for each frame.
    threshold : type = [] of doubles
        An array of thresholds above which labels are included for a frame. Values must be
        between 0 and 1.
    filepath : type = string
        The file path to the folder of all the frames which include test or train in their
        labels.

    Returns
    -------
    avgOccurences (panda): the average of the occurences of error type and respective confidences
                          taken across all labels at a threshold
    distances (panda): for each label, calculates the average distance and standard deviations
                       between the manually labeled points and the dlc labled points
    snapshots ([] of pandas): an array of SnS pandas at the different thresholds

    """

    #Ensures treshold type
    if not isinstance(thresholds, (list, np.ndarray) ):
        raise Exception('thresholds was of the incorrect type. You passed in a [{}] when it should '
                        'have been a list or np.ndarray'.format(str(type(thresholds))[8:-2]))

    #Ensures thresholds is an nparray for boolean checking. Also sorts values in ascending order
    thresholds = np.sort(np.asarray(thresholds))

    #Checks to make sure there is more than 1 value in thresholds
    if thresholds.size<2:
        raise Exception('thresholds is a singular value of {}, not an array or list of multiple '
                        'values'.format(thresholds))

    #Checks that the array is not multi dimensional
    if thresholds.shape != thresholds.flatten().shape:
        raise Exception('you passed in a multidimensional array instead of a 1D list or array')


    t_Below = thresholds[(thresholds<0)] #values less than 0
    t_Above = thresholds[(thresholds>1)] #values greater than 1

    #Checks if any thresholds are repeated
    for i,t in enumerate(thresholds[:-1]):
        if t == thresholds[i+1]:
            raise Exception('{} is a repeated value. Tresholds should only contain unique values '
                            'between 0 and 1'.format(t))

    #Ensures no value is below 0
    if t_Below.size>0:
        raise Exception('{} are below threshold minimum of 0'.format(t_Below))
    #Ensures no value is above 1
    if t_Above.size>0:
        raise Exception('{} are above threshold maximum of 1'.format(t_Above))

    header = pd.MultiIndex.from_product([['Training', 'Test'], errorTypes,
                                         ['# Occurences','Average Confidence']])
    avgOccurences = pd.DataFrame(index = thresholds[:-1], columns = header)

    snapshots = []
    labels = []

    for i, t in enumerate(thresholds[:-1]):
        results, SnS, params = quantifyErrors(trueLabels, testLabels, filepath, threshold=t,
                                     getParams=True, edit=edit, coeff = coeff)

        #initializes the distances matrix, pulls the labels from the first call of quantifyErrors in
        #the first iteration of the loop
        if(i == 0):
            labels = params['labels']
            subHeader = ['Average'] + labels
            header = pd.MultiIndex.from_product([['Training', 'Test'], subHeader,
                                                 ['Distance', 'Standar Deviation']])
            distances = pd.DataFrame(index = thresholds[:-1], columns = header)

        avgOccurences.iloc[i] = list(round(SnS.mean(), 4))
        tempTrainData = results[results['Type'] == 'Training'].iloc[:,3::3] #gets Train distances
        tempTestData = results[results['Type'] == 'Test'].iloc[:,3::3] #gets Test distances
        trainDist = tempTrainData.mean().values.tolist()
        testDist = tempTestData.mean().values.tolist()
        trainVar = tempTrainData.std().values.tolist()
        testVar = tempTestData.std().values.tolist()
        trainDist.insert(0, np.mean(trainDist))
        testDist.insert(0, np.mean(testDist))
        trainVar.insert(0, np.nanstd(tempTrainData, dtype = float))
        testVar.insert(0, np.nanstd(tempTestData, dtype = float))
        distances.iloc[i, ::2] = trainDist+testDist
        distances.iloc[i,1::2] = trainVar+testVar
        snapshots.append(SnS)


    return avgOccurences, distances, snapshots

def plotSnS(trueLabels, testLabels, thresholds, filepath, snapshots=[] , save=True,
               normalize=True):
    """Short summary.

    Parameters
    ----------
    trueLabels : type
        Description of parameter `trueLabels`.
    testLabels : type
        Description of parameter `testLabels`.
    thresholds : type
        Description of parameter `thresholds`.
    filepath : type
        Description of parameter `filepath`.
    snapshots : type
        Description of parameter `snapshots`.
    save : type
        Description of parameter `save`.
    normalize : type
        Description of parameter `normalize`.

    Returns
    -------
    type
        Description of returned object.

    """

    matplotlib.use('WXAgg')

    #If you do not pass in the snapshots
    if not snapshots:
        avgOccurences, distances, snapshots = testThresholds(trueLabels, testLabels, thresholds, filepath)

    plt.style.use('fivethirtyeight')

    #ani = FuncAnimation(plt.gcf(), __animate2, fargs=(snapshots, normalize, thresholds,), interval=2000)

    fig = plt.figure(1)

    for i in range(len(thresholds)):
        keypress = False
        while not keypress:
            keypress = plt.waitforbuttonpress()
        __animate(i,snapshots, normalize, thresholds)

    plt.close()

    #Need to fix writer
    #Writer = matplotlib.animation.writers['ffmpeg']
    #writer = Writer(fps=1)

    #plt.show()
    #ani.save('Error Data.mp4', writer=writer, dpi=1200)

#WIP  in notebooks in different forms. Need more data to continue working on it.
#def Score(snapshots, thresholds, ):


#Private Methods and helper functions (Do Not Call)
#-------------------------------------------------------------------------------------------------#
def __animate(i, snapshots, normalize, thresholds):
    print(i) #Should be printed. Helps ensure plotting is occuring
    print(snapshots)
    fontSize = [14,10,20]
    barWidth = .4
    b = snapshots[i]
    print(b)
    n_groups = b.shape[0]
    if(normalize):
        normalizer = [b['Training'].iloc[0,::2].sum(), b['Test'].iloc[0,::2].sum()]
    else:
        normalizer = [1,1]
    fig = plt.figure(1)
    plt.suptitle("Threshold: " + str(round(thresholds[i],4)), fontsize = fontSize[0])

    for j, errorType in enumerate(errorTypes):
        #fig, ax = plt.subplots()
        plt.subplot(2,2,j+1)
        plt.cla()
        index = np.arange(n_groups)

        r1 = plt.bar(index, (b['Training'][errorType]['# Occurences']) / normalizer[0],
                     barWidth, label = 'Training')

        r2 = plt.bar(index + barWidth, (b['Test'][errorType]['# Occurences']) / normalizer[1],
                     barWidth, label = 'Test')

        plt.xlabel('Label', fontsize = fontSize[0])
        plt.ylabel('% of Labels', fontsize = fontSize[0])
        plt.ylim(0, 1)
        plt.title('Training vs Test Comparison: ' + errorType, fontsize = fontSize[0])
        plt.xticks(index + barWidth/2, (b.index), fontsize = fontSize[0])
        plt.yticks(fontsize = fontSize[0])
        plt.legend(fontsize = fontSize[0])
        #fig.canvas.draw()
        plt.tight_layout()

def __checkInput(trueLabels, testLabels):
    #Ensures true and test labels are correct data type
    if not all(map(lambda x : isinstance(x, (pd.DataFrame, Path, str)), [trueLabels, testLabels])):
        raise Exception('true and test labels must be either a panda dataframe or the h5 output '
                        'files created when training the network. For trueLabels you passed in a '
                        '{} and for testLabels you passed in a {}'.format(str(type(trueLabels)),
                                                                          str(type(testLabels)))
                       )

    #If trueLabels or Testlabels are files, reads them and outputs pandas
    if not isinstance(trueLabels, pd.DataFrame):
        trueLabels = pd.read_hdf(trueLabels)
    if not isinstance(testLabels, pd.DataFrame):
        testLabels = pd.read_hdf(testLabels)

    return trueLabels, testLabels
